# 如何构建一个排名系统

### 1. 简单思考
如果对可扩缩性和速度没有要求的话，那么获取排名很容易。例如，您可以执行以下查询：
``` sql
SELECT count(key) FROM Players WHERE Score > YourScore
```
![批量扫描](https://cloud.google.com/static/datastore/docs/articles/images/fast-and-reliable-ranking-in-datastore/image02.png?hl=zh-cn)

但是这存在较高的性能问题，您要对页面上的每个请求执行该查询吗？当您有上万甚至上百万用户时，这需要多长时间？这种方法速度太慢，成本太高，而且随着规模增加，性能也逐渐变差。

说到性能，您可能会考虑在一些基于内存的存储中间件中维护排名您的数据（例如：Redis 或者 Memcache 等）。这虽然速度很快，但不可靠。以 Redis 为例，当运行内存过大时，Redis 中的数据随时有可能被逐出（或进入不可用状态）。使用仅依赖于内存中键值对的排名服务难以保持一致性和可用性。

### 2. 需求分析

我们需要向用户展示他的分数在全部人中的大致百分比，由于百分比在大数量级下本来就会存在精度模糊，所以一定程度的误差是可以接受的。同时，由于我们使用关系型数据库，而且我们并不太想为这样一个简单的非核心需求引入非关系型数据库，所以维护类似于树或跳表的结构是相对复杂的。同理，我们希望它的实现尽量简单、高效，因为他并非核心业务。基于这些需求，我们参考 **Google** 的一个思路使用了如下方案。

### 3. 如何构建一个高扩展性但存在一定误差的排名系统
#### 3.1 思路

正如前文所述，为每个排名请求查询数据库的成本很高。此替代方法会定期获取所有得分的计数，计算选定得分的排名，并提供这些数据点以用于计算特定用户的排名（或者您为了即时性，也可以选择直接向该系统进行写入，其写入开销也并不算大，但这会使得您的服务失去扩展性，或存在更高的误差。）。

我们将得分的总范围划分为若干个 **“区段”（或者可以称之为桶）**。每个区段包含得分的子范围以及得分在该子范围的用户人数。通过该数据，可找到任意得分的排名的近似值。这些存储分区与排名树中的顶级节点相似，但这种算法仅在一个存储分区内插值，而不是细化到更为详细的节点。
用户从前端检索排名与在后端存储分区上计算排名相分离，从而最大程度减少查找排名所需的时间。在请求某位用户的排名时，将基于该用户的得分找到对应的存储分区。该存储分区包含排名上限和该存储分区内的用户计数。在存储分区内使用[线性插值法](https://zh.wikipedia.org/wiki/%E7%BA%BF%E6%80%A7%E6%8F%92%E5%80%BC)估算存储分区内用户的排名。

系统需要记录每个区段的计数和最高排名（即此区段中可能的最高排名）。对于区段中介于最低得分和最高得分之间的得分，我们可以使用[线性插值法](https://zh.wikipedia.org/wiki/%E7%BA%BF%E6%80%A7%E6%8F%92%E5%80%BC)估算排名。

例如：

![样例](https://cloud.google.com/static/datastore/docs/articles/images/fast-and-reliable-ranking-in-datastore/image08.png?hl=zh-cn)

如果用户得分为 60，那么我们就来查看 [50, 74] 这个范围，通过以下公式，使用计数（该范围内用户/得分个数）(42) 和最高排名 (5) 来计算该用户的排名：
> rank = 5  + (74 - 60)*42/(74 - 50) =  30

这样做的好处是，我们的 FindRank 方法的开销与用户人数无关，换句话说，我们近似的实现了一种 O(1) 级别的方法，这极大地保证了我们服务的性能。而且由于计算存储分区的最高排名是通过计划作业在后台完成的，因此无需保持存储分区数据同步即可更新用户得分。所以此方法不会对更新用户得分的吞吐量造成限制

#### 3.2 部分核心实现参考

``` go
 type Bucket struct {
	Count     int
	UpperRank int
	LowScore  float64
	HighScore float64

	LowerBound float64
}
```
``` go
func (b *Bucket) GetRank(reqSource float64) (int, error) {
	if reqSource < b.LowerBound {
		return 0, errors.New("source value is less than lower bound")
	}
	// Use linear interpolation to estimate ranking
	rank := int(math.Ceil((b.HighScore - reqSource) * float64(b.Count) / (b.HighScore - b.LowScore)))
	return rank, nil
}
```

#### 3.3 准确性

存储分区方法的准确性取决于存储分区数、用户排名和得分分布。

![桶的数量对准确性的影响](https://cloud.google.com/static/datastore/docs/articles/images/fast-and-reliable-ranking-in-datastore/image07.png?hl=zh-cn)

如上图，测试对象为 1 万名用户，其得分在 [0-9999] 范围内均匀分布。即使只有 5 个存储分区，相对误差也在 1％ 左右。排名较高的用户，准确性反而较低，主要是因为在只考虑高得分时，大数法则并不适用。在很多情况下，可以考虑使用更为精确的算法来计算前一千或两千名用户的排名。由于需要追踪的用户人数更少，更新的聚合速率也相应更低，因此显著降低了问题的复杂性。

![小数据集下的效果](https://cloud.google.com/static/datastore/docs/articles/images/fast-and-reliable-ranking-in-datastore/image00.png?hl=zh-cn)

当我们使用了 100 位用户人数来测试小规模数据集的准确性。通过计算 0 到 100 之间的 4 个随机数字的平均值生成每个得分，其近似为得分的正态分布。通过在 10 个存储分区上结合使用全局查询方法和线性插值法计算出估算排名。可以看出，即使对于非常小的数据集和非均匀分布，结果也非常理想。

### 4. 思考：如果构建一个满足高可用性又快速准确的排名系统
**Google**的工程师们出于他们的需求，就选择并设计了这样一套方案，我们将解读他们方案的核心实现。（因为**Google**的实现中使用了很多他们的云服务，所以在解读中，我们将用具有类似行为的通用中间件来替代他们）

#### 4.1 选择核心数据结构/算法

为了实现高性能、高准确性的排名，我们可以也只好选用一种 O(log n) 级别的算法来帮助查找元素。这样的算法有很多二叉树、红黑树或 B 树等树算法或者跳表等链式算法都能够以 O(log n) 时间复杂度执行。**Google**使用了 Google Code Jam 排名库，它由 Google 工程师编写，适用于 Datastore。其公开了两个方法：1.SetScore 用于设置用户得分。2.FindRank 用于获取给定得分的排名

![在三叉树中获取得分排名](https://cloud.google.com/static/datastore/docs/articles/images/fast-and-reliable-ranking-in-datastore/image05.png?hl=zh-cn)

由于用户/得分对通过 SetScore 方法创建和更新，因此 Code Jam 排名库会构建一个 N 叉树（如图）。例如，我们构建一个可计算得分在 0 - 80 范围内的用户人数的三叉树。该库将包含三个数字的根节点存储为一个实体。每个数字分别对应得分在 0 - 26、27 - 53 和 54 - 80 范围内的用户人数。根节点针对每个范围都具有一个子节点，依次包含子范围的下一级范围内的用户对应的三个值。该层次结构需要 4 个级别来存储 81 个不同得分值对应的用户人数。

同样，调用 SetScore 只需要更新 4 个实体。即使您具有大量不同得分，Datastore 访问也只会按 O(log n) 增加，不受用户人数的影响。实际上，Code Jam 排名库使用 100（而不是 3）作为每个节点的值的默认数，因此仅需访问 2 个（得分范围大于 10 万时，则为 3 个）实体。

#### 4.2 并发问题
在负载测试期间，**Google** 发现了 Code Jam 排名库存在一个严重限制。它在更新吞吐量方面的可扩展性非常低。当他将负载增加到每秒三次更新时，该库开始返回事务重试错误。显然，该库无法满足 Applibot 每秒 300 次更新的要求。它大约只能处理该吞吐量的 1%。

为什么？其原因在于保持树的一致性。在 Datastore 中，更新一个事务中的多个实体时，必须使用实体组来确保高度一致性。Code Jam 排名库使用一个实体组保存整个树，以确保树元素中计数的一致性。但 Datastore 中的实体组具有性能限制。在一个实体组上，Datastore 仅支持每秒大约一个事务。此外，如果在并发事务中修改同一实体组，则可能会失败，因此必须重试。Code Jam 排名库具有高度一致性、事务性并且相当快速，但不支持大量的并发更新。

#### 4.3 解决并发问题的一种思路
为了解决这个问题，**Google**采用了作业聚合的思路，您可以在其他存储产品（例如 VoltDb 和 Redis）中发现类似构想。简单来说，作业聚合的基本构想是使用单个线程处理批量更新。由于实体组中仅有一个线程并且仅有一个打开的事务，因此并发更新不会导致事务失败。作业聚合模式有一个缺点：它只使用一个线程聚合所有更新，这会限制将更新发送到 Datastore 的速度。但为了并发性，我们得做出取舍。

**Google**采用了类似消息队列的中间件（实际上是 App Engine 中的拉取队列）。后端实例中有一个处于无限循环的单线程，该线程持续从队列中尽可能多地拉取任务。该线程将每个更新请求传递到 Code Jam 排名库，该库在单个事务中批量执行这些请求。事务可能打开一秒钟或更长时间，但由于该库和 Datastore 受单线程驱动，因此不存在争用和并发修改问题。这使得我们通过异步能够支持并发请求。

#### 4.4 关于 Google 云服务的建议

**Google**的解决方案架构师 Michael Tang 在文档里推荐使用队列分片的变通方法。他建议不要仅使用一个队列，而是将负载分配到多个队列中。这是由于 App Engine 中的拉取队列依赖于 [Bigtable](https://static.googleusercontent.com/media/research.google.com/en/us/archive/bigtable-osdi06.pdf) 作为其永久层。当一个  [Bigtable](https://static.googleusercontent.com/media/research.google.com/en/us/archive/bigtable-osdi06.pdf)  片增加到一定程度时，就会分成多个片。该片在拆分时会停止传递任务，这导致了队列在高速接收任务时的性能波动。每个队列都可以存储在不同的  [Bigtable](https://static.googleusercontent.com/media/research.google.com/en/us/archive/bigtable-osdi06.pdf)  片服务器上，以最大程度地减少片拆分的影响和保持较高的任务处理速度。当一个队列处理拆分时，其他队列将继续工作，而且分片会减少每个队列的负载，因此可降低拆分片发生的频率。

#### 4.5 评价

如果循环或后端实例出现错误或意外关停，更新任务会保留在任务队列中，以便在实例重启时得到处理。在生产系统中，您可能会让另一个后端充当处于备用模式的监视者，在第一个实例出现故障时准备进行接替。这样我们就保证了服务的高性能、高可用
上述建议的解决方案具有若干优点和两个缺点：

- 优点：
  - 快速：FindRank 调用仅需数百毫秒或更少时间。SetScore 只调度一个任务，后端在几秒钟内处理该任务
  - 在 Datastore 中具备高度一致性和持久性
  - 排名准确
  - 可扩展至任意数量的用户
- 缺点：
  - 吞吐量存在限制（在 google 的实现中约为 300 次更新/秒）
  - 实现起来具有一定复杂性，特别是当您因为语言社区没有类似于 Code Jam 排名库的库，需要自行构建时


